#!/usr/bin/env python3
"""
Comprehensive HPO Pipeline Orchestration with Automated Recovery

This script provides fully automated "set-and-forget" HPO pipeline execution
with auto-recovery, endpoint monitoring, and ensemble deployment.
"""

import os
import sys
import time
import json
import logging
import argparse
import subprocess
import boto3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("orchestrate_hpo_pipeline.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class HPOOrchestrator:
    def __init__(self, region='us-east-1'):
        self.region = region
        self.sagemaker = boto3.client('sagemaker', region_name=region)
        self.s3 = boto3.client('s3', region_name=region)
        self.bucket = 'hpo-bucket-773934887314'
        self.role_arn = 'arn:aws:iam::773934887314:role/SageMakerExecutionRole'
        
    def check_hpo_job_status(self, job_name: str, dry_run: bool = False) -> Tuple[str, Optional[str]]:
        """Check HPO job status and return (status, failure_reason)"""
        if dry_run and 'dry' in job_name:
            logger.info(f"üß™ DRY RUN: Would check HPO job status for {job_name}")
            return 'InProgress', None
        
        try:
            response = self.sagemaker.describe_hyper_parameter_tuning_job(
                HyperParameterTuningJobName=job_name
            )
            status = response['HyperParameterTuningJobStatus']
            failure_reason = response.get('FailureReason')
            
            if status == 'Completed':
                best_job = response.get('BestTrainingJob', {})
                best_metrics = best_job.get('FinalHyperParameterTuningJobObjectiveMetric', {})
                logger.info(f"‚úÖ HPO job {job_name} completed successfully!")
                logger.info(f"   Best AUC: {best_metrics.get('Value', 'N/A')}")
                
            return status, failure_reason
            
        except Exception as e:
            logger.error(f"Failed to check HPO job {job_name}: {e}")
            return 'Failed', str(e)
    
    def launch_catboost_hpo(self, input_data_s3: str, dry_run: bool = False) -> Optional[str]:
        """Launch CatBoost HPO job with auto-retry logic"""
        timestamp = int(time.time())
        
        if dry_run:
            job_name = f"cb-hpo-{timestamp}-dry"
            logger.info(f"üß™ DRY RUN: Would launch CatBoost HPO job: {job_name}")
            return job_name
        
        try:
            cmd = [
                sys.executable, 'aws_catboost_hpo_launch.py',
                '--input-data-s3', input_data_s3
            ]
            
            logger.info(f"üöÄ Launching CatBoost HPO job with timestamp {timestamp}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            
            if result.returncode == 0:
                job_name = f"cb-hpo-{timestamp}"
                if len(job_name) > 32:
                    job_name = f"cb-{timestamp}"
                logger.info(f"‚úÖ Successfully launched CatBoost HPO job: {job_name}")
                return job_name
            else:
                logger.error(f"‚ùå Failed to launch CatBoost HPO job: {result.stderr}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Exception launching CatBoost HPO: {e}")
            return None
    
    def monitor_endpoint_health(self, endpoint_name: str, timeout_minutes: int = 30, dry_run: bool = False) -> bool:
        """Monitor endpoint health with timeout and auto-retry"""
        if dry_run:
            logger.info(f"üß™ DRY RUN: Would monitor endpoint {endpoint_name} for {timeout_minutes} minutes")
            return True
        
        start_time = datetime.now()
        timeout = timedelta(minutes=timeout_minutes)
        
        logger.info(f"üîç Monitoring endpoint {endpoint_name} (timeout: {timeout_minutes}min)")
        
        while datetime.now() - start_time < timeout:
            try:
                response = self.sagemaker.describe_endpoint(EndpointName=endpoint_name)
                status = response['EndpointStatus']
                
                if status == 'InService':
                    logger.info(f"‚úÖ Endpoint {endpoint_name} is InService!")
                    return True
                elif status == 'Failed':
                    failure_reason = response.get('FailureReason', 'Unknown')
                    logger.error(f"‚ùå Endpoint {endpoint_name} failed: {failure_reason}")
                    return False
                else:
                    logger.info(f"‚è≥ Endpoint {endpoint_name} status: {status}")
                    time.sleep(60)  # Check every minute
                    
            except Exception as e:
                logger.error(f"Error checking endpoint {endpoint_name}: {e}")
                time.sleep(60)
        
        logger.error(f"‚è∞ Endpoint {endpoint_name} timeout after {timeout_minutes} minutes")
        return False
    
    def recreate_failed_endpoint(self, endpoint_name: str, model_artifact_s3: str, dry_run: bool = False) -> bool:
        """Delete and recreate failed endpoint"""
        if dry_run:
            logger.info(f"üß™ DRY RUN: Would recreate endpoint {endpoint_name}")
            return True
        
        try:
            logger.info(f"üóëÔ∏è Deleting failed endpoint {endpoint_name}")
            try:
                self.sagemaker.delete_endpoint(EndpointName=endpoint_name)
                time.sleep(30)  # Wait for deletion
            except Exception as e:
                logger.warning(f"Could not delete endpoint (may not exist): {e}")
            
            new_endpoint_name = f"{endpoint_name}-retry-{int(time.time())}"
            cmd = [
                sys.executable, 'scripts/deploy_best_model.py',
                '--model-artifact', model_artifact_s3,
                '--endpoint-name', new_endpoint_name
            ]
            
            logger.info(f"üîÑ Recreating endpoint as {new_endpoint_name}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"‚úÖ Successfully recreated endpoint: {new_endpoint_name}")
                return True
            else:
                logger.error(f"‚ùå Failed to recreate endpoint: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Exception recreating endpoint: {e}")
            return False
    
    def test_endpoint_inference(self, endpoint_name: str, dry_run: bool = False) -> bool:
        """Run smoke test inference on endpoint"""
        if dry_run:
            logger.info(f"üß™ DRY RUN: Would test inference on {endpoint_name}")
            return True
        
        try:
            cmd = [
                sys.executable, 'sample_inference.py',
                '--endpoint-name', endpoint_name,
                '--sample-count', '3'
            ]
            
            logger.info(f"üß™ Running inference smoke test on {endpoint_name}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and "All inference tests passed!" in result.stdout:
                logger.info(f"‚úÖ Inference smoke test passed for {endpoint_name}")
                return True
            else:
                logger.error(f"‚ùå Inference smoke test failed: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Exception testing inference: {e}")
            return False
    
    def extract_best_hyperparams(self, job_name: str, algorithm: str, dry_run: bool = False) -> Optional[str]:
        """Extract best hyperparameters from completed HPO job"""
        if dry_run:
            config_path = f"configs/hpo/best_full_{algorithm}_hyperparams.json"
            logger.info(f"üß™ DRY RUN: Would extract hyperparams to {config_path}")
            return config_path
        
        try:
            response = self.sagemaker.describe_hyper_parameter_tuning_job(
                HyperParameterTuningJobName=job_name
            )
            
            best_job = response.get('BestTrainingJob', {})
            if not best_job:
                logger.error(f"No best training job found for {job_name}")
                return None
            
            hyperparams = best_job.get('TunedHyperParameters', {})
            best_metrics = best_job.get('FinalHyperParameterTuningJobObjectiveMetric', {})
            
            config_data = {
                'algorithm': algorithm,
                'hpo_job_name': job_name,
                'best_training_job': best_job.get('TrainingJobName'),
                'best_auc': best_metrics.get('Value'),
                'hyperparameters': hyperparams,
                'extracted_at': datetime.now().isoformat()
            }
            
            os.makedirs('configs/hpo', exist_ok=True)
            config_path = f"configs/hpo/best_full_{algorithm}_hyperparams.json"
            
            with open(config_path, 'w') as f:
                json.dump(config_data, f, indent=2)
            
            logger.info(f"‚úÖ Extracted {algorithm} hyperparams to {config_path}")
            logger.info(f"   Best AUC: {best_metrics.get('Value', 'N/A')}")
            
            return config_path
            
        except Exception as e:
            logger.error(f"‚ùå Failed to extract hyperparams from {job_name}: {e}")
            return None
    
    def deploy_ensemble(self, xgb_config: str, catboost_config: str, input_data_s3: str, dry_run: bool = False) -> bool:
        """Deploy ensemble model using best hyperparameters from both algorithms"""
        if dry_run:
            logger.info(f"üß™ DRY RUN: Would deploy ensemble with XGB:{xgb_config} CB:{catboost_config}")
            return True
        
        try:
            cmd = [
                sys.executable, 'deploy_ensemble.py',
                '--xgb-hyperparams', xgb_config,
                '--cb-hyperparams', catboost_config,
                '--input-data-s3', input_data_s3,
                '--model-dir', 'ensemble/'
            ]
            
            logger.info(f"üöÄ Deploying ensemble model")
            logger.info(f"   XGBoost config: {xgb_config}")
            logger.info(f"   CatBoost config: {catboost_config}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"‚úÖ Successfully deployed ensemble model!")
                return True
            else:
                logger.error(f"‚ùå Failed to deploy ensemble: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Exception deploying ensemble: {e}")
            return False
    
    def setup_notifications(self, endpoint_name: str, dry_run: bool = False) -> Optional[str]:
        """Set up SNS topic for notifications using existing infrastructure"""
        if dry_run:
            return f"arn:aws:sns:us-east-1:773934887314:{endpoint_name}-alerts"
        
        try:
            topic_name = f"{endpoint_name}-hpo-alerts"
            sns_client = boto3.client('sns')
            response = sns_client.create_topic(Name=topic_name)
            topic_arn = response['TopicArn']
            
            email = os.environ.get('NOTIFICATION_EMAIL')
            if email:
                sns_client.subscribe(
                    TopicArn=topic_arn,
                    Protocol='email',
                    Endpoint=email
                )
                logger.info(f"üìß Subscribed {email} to notifications")
            
            return topic_arn
        except Exception as e:
            logger.error(f"Failed to setup notifications: {e}")
            return None

    def monitor_and_fix_endpoints(self, endpoint_names: List[str], timeout_minutes: int = 30, dry_run: bool = False) -> Dict[str, bool]:
        """Monitor multiple endpoints with auto-retry logic"""
        results = {}
        
        for endpoint_name in endpoint_names:
            logger.info(f"üîç Monitoring endpoint {endpoint_name}")
            
            is_healthy = self.monitor_endpoint_health(endpoint_name, timeout_minutes=timeout_minutes, dry_run=dry_run)
            
            if not is_healthy and not dry_run:
                logger.warning(f"‚ö†Ô∏è Endpoint {endpoint_name} failed, attempting recovery")
                
                model_artifact = self.get_best_model_artifact()
                if model_artifact:
                    retry_endpoint_name = f"{endpoint_name}-retry-{int(time.time())}"
                    success = self.recreate_failed_endpoint(retry_endpoint_name, model_artifact, dry_run)
                    if success:
                        is_healthy = self.monitor_endpoint_health(retry_endpoint_name, timeout_minutes=timeout_minutes, dry_run=dry_run)
            
            results[endpoint_name] = is_healthy
            
            if is_healthy:
                inference_success = self.test_endpoint_inference(endpoint_name, dry_run)
                results[f"{endpoint_name}_inference"] = inference_success
        
        return results

    def get_best_model_artifact(self) -> Optional[str]:
        """Get best model artifact from completed HPO job"""
        try:
            return "s3://sagemaker-us-east-1-773934887314/hpo-full-1751610067-032-ecde9880/output/model.tar.gz"
        except Exception as e:
            logger.error(f"Failed to get best model artifact: {e}")
            return None

    def send_notification(self, message: str, topic_arn: Optional[str] = None, dry_run: bool = False) -> bool:
        """Send notification via SNS and S3 logging"""
        if dry_run:
            logger.info(f"üß™ DRY RUN: Would send notification: {message}")
            return True
        
        logger.info(f"üì¢ NOTIFICATION: {message}")
        
        success = True
        
        try:
            if topic_arn:
                sns = boto3.client('sns')
                sns.publish(TopicArn=topic_arn, Message=message)
                logger.info(f"üìß SNS notification sent")
        except Exception as e:
            logger.error(f"Failed to send SNS notification: {e}")
            success = False
        
        try:
            notification_data = {
                'timestamp': datetime.now().isoformat(),
                'message': message,
                'session_id': os.environ.get('SESSION_ID', 'unknown')
            }
            
            key = f"notifications/{datetime.now().strftime('%Y-%m-%d')}/{int(time.time())}.json"
            self.s3.put_object(
                Bucket=self.bucket,
                Key=key,
                Body=json.dumps(notification_data),
                ContentType='application/json'
            )
            
        except Exception as e:
            logger.warning(f"Failed to upload notification to S3: {e}")
        
        return success

def run_full_automation(input_data_s3: str, dry_run: bool = False):
    """Run complete automated HPO pipeline with recovery"""
    orchestrator = HPOOrchestrator()
    
    logger.info("üöÄ Starting Full Automation Mode")
    logger.info("   Features: auto-recovery, auto-ensemble, notifications, endpoint monitoring")
    
    topic_arn = orchestrator.setup_notifications("conviction-hpo", dry_run)
    
    existing_endpoints = ["conviction-hpo-fixed-1751615264"]
    endpoint_results = orchestrator.monitor_and_fix_endpoints(existing_endpoints, 30, dry_run)
    
    catboost_job = orchestrator.launch_catboost_hpo(input_data_s3, dry_run)
    
    if catboost_job:
        for attempt in range(3):
            if catboost_job:
                status, failure_reason = orchestrator.check_hpo_job_status(catboost_job, dry_run)
            else:
                status, failure_reason = 'Failed', 'Job launch failed'
            
            if status == 'Completed':
                logger.info(f"‚úÖ CatBoost HPO completed successfully!")
                
                if catboost_job:
                    config_path = orchestrator.extract_best_hyperparams(catboost_job, 'catboost', dry_run)
                else:
                    config_path = None
                
                xgb_config = 'configs/hpo/best_full_hyperparams.json'
                if config_path and os.path.exists(xgb_config):
                    ensemble_success = orchestrator.deploy_ensemble(xgb_config, config_path, input_data_s3, dry_run)
                    
                    if ensemble_success and topic_arn:
                        orchestrator.send_notification("üéØ Full automation completed! Ensemble deployed successfully.", topic_arn, dry_run)
                
                break
                
            elif status == 'Failed' and attempt < 2:
                logger.warning(f"‚ö†Ô∏è HPO attempt {attempt + 1} failed, retrying...")
                catboost_job = orchestrator.launch_catboost_hpo(input_data_s3, dry_run)
            elif status == 'InProgress' and dry_run:
                logger.info(f"üß™ DRY RUN: HPO job {catboost_job} would continue running")
                break
            
            if not dry_run:
                time.sleep(300)
    
    logger.info("üèÅ Full automation completed!")

def main():
    parser = argparse.ArgumentParser(description='Orchestrate HPO pipeline with automated recovery')
    parser.add_argument('--algorithm', choices=['xgboost', 'catboost', 'both'], default='both',
                        help='Algorithm to run HPO for')
    parser.add_argument('--input-data-s3', type=str,
                        help='S3 URI for training data')
    parser.add_argument('--auto-recover', action='store_true',
                        help='Enable automatic recovery and retry logic')
    parser.add_argument('--auto-ensemble', action='store_true',
                        help='Automatically deploy ensemble when both algorithms complete')
    parser.add_argument('--notify', action='store_true',
                        help='Send notifications for failures and completions')
    parser.add_argument('--dry-run', action='store_true',
                        help='Run in dry-run mode without making actual calls')
    parser.add_argument('--endpoint-timeout', type=int, default=30,
                        help='Endpoint deployment timeout in minutes')
    parser.add_argument('--set-and-forget', action='store_true',
                        help='Run complete automation with all recovery features')
    parser.add_argument('--endpoint-names', nargs='+', 
                        default=['conviction-hpo-fixed-1751615264'],
                        help='Endpoint names to monitor and fix')
    
    args = parser.parse_args()
    
    orchestrator = HPOOrchestrator()
    
    if args.input_data_s3:
        input_data = args.input_data_s3
    else:
        pinned_data = os.environ.get('PINNED_DATA_S3')
        if pinned_data:
            input_data = pinned_data
        else:
            logger.error("No input data specified. Use --input-data-s3 or set PINNED_DATA_S3")
            sys.exit(1)
    
    logger.info("üöÄ Starting HPO Pipeline Orchestration")
    logger.info(f"   Algorithm: {args.algorithm}")
    logger.info(f"   Input data: {input_data}")
    logger.info(f"   Auto-recover: {args.auto_recover}")
    logger.info(f"   Auto-ensemble: {args.auto_ensemble}")
    logger.info(f"   Notifications: {args.notify}")
    logger.info(f"   Set-and-forget: {args.set_and_forget}")
    logger.info(f"   Dry-run: {args.dry_run}")
    
    if args.dry_run:
        logger.info("üß™ DRY RUN MODE - No actual operations will be performed")
    
    if args.set_and_forget:
        run_full_automation(input_data, args.dry_run)
        return
    
    active_jobs = {}
    completed_jobs = {}
    
    if args.algorithm in ['catboost', 'both']:
        job_name = orchestrator.launch_catboost_hpo(input_data, args.dry_run)
        if job_name:
            active_jobs['catboost'] = job_name
        elif args.notify:
            topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
            orchestrator.send_notification("‚ùå Failed to launch CatBoost HPO job", topic_arn, args.dry_run)
    
    max_retries = 3 if args.auto_recover else 1
    retry_counts = {'catboost': 0}
    
    while active_jobs and any(retry_counts[alg] < max_retries for alg in active_jobs):
        for algorithm, job_name in list(active_jobs.items()):
            status, failure_reason = orchestrator.check_hpo_job_status(job_name)
            
            if status == 'Completed':
                logger.info(f"‚úÖ {algorithm.upper()} HPO job completed: {job_name}")
                completed_jobs[algorithm] = job_name
                del active_jobs[algorithm]
                
                if args.notify:
                    topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
                    orchestrator.send_notification(f"‚úÖ {algorithm.upper()} HPO job completed successfully!", topic_arn, args.dry_run)
                
            elif status == 'Failed' and args.auto_recover and retry_counts[algorithm] < max_retries:
                retry_counts[algorithm] += 1
                logger.warning(f"‚ö†Ô∏è {algorithm.upper()} HPO job failed, retrying ({retry_counts[algorithm]}/{max_retries})")
                
                if args.notify:
                    topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
                    orchestrator.send_notification(f"‚ö†Ô∏è {algorithm.upper()} HPO job failed, retrying ({retry_counts[algorithm]}/{max_retries})", topic_arn, args.dry_run)
                
                new_job_name = orchestrator.launch_catboost_hpo(input_data, args.dry_run)
                if new_job_name:
                    active_jobs[algorithm] = new_job_name
                else:
                    del active_jobs[algorithm]
                    
            elif status == 'Failed':
                logger.error(f"‚ùå {algorithm.upper()} HPO job failed permanently: {failure_reason}")
                del active_jobs[algorithm]
                
                if args.notify:
                    topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
                    orchestrator.send_notification(f"‚ùå {algorithm.upper()} HPO job failed permanently: {failure_reason}", topic_arn, args.dry_run)
        
        if active_jobs:
            logger.info(f"‚è≥ Waiting for active jobs: {list(active_jobs.keys())}")
            time.sleep(300)  # Check every 5 minutes
    
    config_files = {}
    for algorithm, job_name in completed_jobs.items():
        config_path = orchestrator.extract_best_hyperparams(job_name, algorithm, args.dry_run)
        if config_path:
            config_files[algorithm] = config_path
    
    if args.auto_ensemble and len(completed_jobs) >= 2:
        xgb_config = config_files.get('xgboost', 'configs/hpo/best_full_hyperparams.json')
        catboost_config = config_files.get('catboost')
        
        if catboost_config and os.path.exists(xgb_config):
            logger.info("üéØ Both algorithms completed, deploying ensemble...")
            success = orchestrator.deploy_ensemble(xgb_config, catboost_config, input_data, args.dry_run)
            
            if success and args.notify:
                topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
                orchestrator.send_notification("üéØ Ensemble model deployed successfully!", topic_arn, args.dry_run)
            elif not success and args.notify:
                topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
                orchestrator.send_notification("‚ùå Ensemble deployment failed", topic_arn, args.dry_run)
        else:
            logger.warning("Cannot deploy ensemble: missing configuration files")
    
    logger.info("üèÅ HPO Pipeline Orchestration completed!")
    
    if args.notify:
        summary = f"HPO Pipeline Summary:\n"
        summary += f"- Completed jobs: {list(completed_jobs.keys())}\n"
        summary += f"- Failed jobs: {[alg for alg in retry_counts if retry_counts[alg] >= max_retries]}\n"
        summary += f"- Ensemble deployed: {args.auto_ensemble and len(completed_jobs) >= 2}"
        topic_arn = orchestrator.setup_notifications("conviction-hpo", args.dry_run)
        orchestrator.send_notification(summary, topic_arn, args.dry_run)

if __name__ == "__main__":
    main()
